{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as ds\n",
    "import torch.nn as nn \n",
    "from torchtext.datasets.babi import BABI20, BABI20Field\n",
    "import torchtext.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E(p, v): \n",
    "    return torch.bmm(p.transpose(1, 2), v)\n",
    "\n",
    "def KL(p, q): \n",
    "    return ds.kl_divergence(p, q)\n",
    "\n",
    "def Cat(scores, one_hot=True): \n",
    "    if one_hot:\n",
    "        return ds.OneHotCategorical(logits=scores)\n",
    "    else:\n",
    "        return ds.Categorical(logits=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, src_encoder, query_encoder):\n",
    "        super(Attention, self).__init__()\n",
    "        self.src_encoder = src_encoder\n",
    "        self.query_encoder = query_encoder\n",
    "        \n",
    "    def forward(self, src, query):\n",
    "        src_vecs = self.src_encoder(src)\n",
    "        query_vecs = self.query_encoder(query)\n",
    "        attention = torch.bmm(src_vecs, query_vecs.transpose(1, 2))\n",
    "        return src_vecs, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, out_classes, hidden_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.prediction_network = \n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_size, hidden_size),\n",
    "                nn.ReLUL(),\n",
    "                nn.Linear(hidden_size, out_classes)) \n",
    "\n",
    "    def forward(self, context):\n",
    "        return self.prediction_network(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = BABI20.iters(batch_size=100, task = 1,)\n",
    "QUERY = train.dataset.fields[\"query\"]\n",
    "STORY = train.dataset.fields[\"story\"]\n",
    "ANSWER = train.dataset.fields[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, last_only=False):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab_size, hidden_size) \n",
    "        self.encoder = nn.LSTM(hidden_size=hidden_size,\n",
    "                               input_size=hidden_size,\n",
    "                               bidirectional=not last_only) \n",
    "        self.last_only = last_only\n",
    "        \n",
    "    def forward(self, text):\n",
    "        x = self.lut(text)\n",
    "        x, _ = self.encoder(x)\n",
    "        if self.last_only:\n",
    "            return x[:, -1:]\n",
    "        else:\n",
    "            return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(41.3210)\n",
      "tensor(32.2808)\n",
      "tensor(32.5659)\n",
      "tensor(27.1223)\n",
      "tensor(25.9738)\n",
      "tensor(24.0419)\n",
      "tensor(20.5931)\n",
      "tensor(13.1045)\n",
      "tensor(8.4104)\n",
      "tensor(10.7441)\n",
      "tensor(14.7080)\n",
      "tensor(13.8520)\n",
      "tensor(10.5503)\n",
      "tensor(9.0310)\n",
      "tensor(8.5378)\n",
      "tensor(5.5080)\n",
      "tensor(6.2666)\n",
      "tensor(5.4611)\n",
      "tensor(3.6705)\n",
      "tensor(5.9019)\n",
      "tensor(8.0330)\n",
      "tensor(5.3569)\n",
      "tensor(4.6592)\n",
      "tensor(4.0378)\n",
      "tensor(5.2231)\n",
      "tensor(3.7877)\n",
      "tensor(3.6607)\n",
      "tensor(5.5091)\n",
      "tensor(4.3207)\n",
      "tensor(4.5140)\n",
      "tensor(4.5242)\n",
      "tensor(4.8852)\n",
      "tensor(4.6404)\n",
      "tensor(4.0859)\n",
      "tensor(3.7199)\n",
      "tensor(4.0425)\n",
      "tensor(4.2135)\n",
      "tensor(2.6278)\n",
      "tensor(4.0896)\n",
      "tensor(3.4656)\n",
      "tensor(3.4424)\n",
      "tensor(3.8586)\n",
      "tensor(3.5965)\n",
      "tensor(3.1555)\n",
      "tensor(3.3140)\n",
      "tensor(2.7481)\n",
      "tensor(4.3643)\n",
      "tensor(4.0031)\n",
      "tensor(3.2112)\n",
      "tensor(2.9813)\n",
      "tensor(3.3521)\n",
      "tensor(3.8359)\n",
      "tensor(3.8734)\n",
      "tensor(3.7003)\n",
      "tensor(3.9962)\n",
      "tensor(2.8786)\n",
      "tensor(2.9738)\n",
      "tensor(4.3933)\n",
      "tensor(2.5862)\n",
      "tensor(2.5975)\n",
      "tensor(2.2397)\n",
      "tensor(3.0304)\n",
      "tensor(2.9350)\n",
      "tensor(2.5647)\n",
      "tensor(2.6183)\n",
      "tensor(2.3786)\n",
      "tensor(3.5077)\n",
      "tensor(2.8934)\n",
      "tensor(2.2497)\n",
      "tensor(2.5913)\n",
      "tensor(2.5810)\n",
      "tensor(2.9680)\n",
      "tensor(2.4013)\n",
      "tensor(2.1139)\n",
      "tensor(2.9194)\n",
      "tensor(2.7672)\n",
      "tensor(2.7160)\n",
      "tensor(2.2610)\n",
      "tensor(2.5602)\n",
      "tensor(2.6594)\n",
      "tensor(2.3142)\n",
      "tensor(2.4058)\n",
      "tensor(2.2147)\n",
      "tensor(2.2901)\n",
      "tensor(2.8127)\n",
      "tensor(2.2638)\n",
      "tensor(2.3634)\n",
      "tensor(2.2307)\n",
      "tensor(2.5051)\n",
      "tensor(2.3977)\n",
      "tensor(1.9941)\n",
      "tensor(2.2432)\n",
      "tensor(2.4850)\n",
      "tensor(2.3291)\n",
      "tensor(2.3328)\n",
      "tensor(2.1522)\n",
      "tensor(2.2580)\n",
      "tensor(2.2912)\n",
      "tensor(2.1068)\n",
      "tensor(2.2608)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Module()\n",
    "model.alignment = Attention(Encoder(len(STORY.vocab), 50),\n",
    "                            Encoder(len(QUERY.vocab), 100, last_only=True)\n",
    "                           )\n",
    "model.generator = Generator(len(ANSWER.vocab), 100)\n",
    "#model.inference = Inferer(len(ANSWER.vocab), 20)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "typ = \"soft\"\n",
    "for epoch in range(10):\n",
    "    for batch in test:\n",
    "        opt.zero_grad()\n",
    "        x = batch.story.view(batch.story.shape[0], -1)\n",
    "        x_tilde = batch.query\n",
    "        y = batch.answer.squeeze(1)\n",
    "\n",
    "        v, theta = model.alignment.forward(x, x_tilde)\n",
    "        p = Cat(theta)\n",
    "        def soft():\n",
    "            context = E(p.probs, v)\n",
    "            logits = model.generator(context).squeeze(1)\n",
    "            p_y = Cat(logits,one_hot=False)\n",
    "            #print(logits[0], y[0])\n",
    "            return -p_y.log_prob(y)\n",
    "\n",
    "        def hard():\n",
    "            context = E(p.sample(), v)\n",
    "            logits = model.generator(context).squeeze(1)\n",
    "            p_y = Cat(logits, one_hot=False)    \n",
    "            return -p_y.log_prob(y) \n",
    "\n",
    "        def enum():\n",
    "            logits = model.generator(v)\n",
    "            p_y = Cat(logits)\n",
    "            return E(p.probs, p_y.log_prob(y).unsqueeze(2))\n",
    "\n",
    "        def vae():\n",
    "            q = model.inference(x, x_tilde, y)\n",
    "            context = E(q.sample(), v)\n",
    "            p_y = Cat(model.generator(context).squeeze(1))\n",
    "            return p_y.log_prob(y) + KL(p, q)\n",
    "\n",
    "        if typ == \"soft\":\n",
    "            loss = soft()\n",
    "        elif typ == \"hard\":\n",
    "            loss = hard()\n",
    "        elif typ == \"enum\":\n",
    "            loss = enum()\n",
    "        elif typ == \"vae\":\n",
    "            loss = vae()\n",
    "\n",
    "        #loss = E(p, p_y.log_prob(y.unsqueeze()))\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        print(loss.detach())\n",
    "        opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.LongTensor of size ()]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.Categorical(logits=torch.autograd.Variable(torch.Tensor([0.2, 0.8]))\n",
    "              ).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.Categorical()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
