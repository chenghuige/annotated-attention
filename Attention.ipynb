{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as ds\n",
    "import torch.nn as nn\n",
    "from torchtext.datasets.babi import BABI20, BABI20Field\n",
    "import torchtext.data\n",
    "#%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: bAbi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train, val, test = BABI20.iters(batch_size=20, task=1, device=torch.device(0))\n",
    "data = train.dataset\n",
    "QUERY, STORY, ANSWER = data.fields[\"query\"], data.fields[\"story\"], data.fields[\"answer\"]\n",
    "\n",
    "\n",
    "def wrap(data):\n",
    "    return ((batch.story, batch.query, batch.answer.squeeze(1)) for batch in data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_instance(x, x_tilde, y, p=None, p_y=None):\n",
    "    print(\"Correct answer: \", ANSWER.vocab.itos[y])\n",
    "    print(\"Story: \")\n",
    "    for i, s in enumerate(x):\n",
    "        for k, w in enumerate(s):\n",
    "            if STORY.vocab.itos[w] != \"<pad>\":\n",
    "                print(STORY.vocab.itos[w], end=\" \")\n",
    "            elif k == 0:\n",
    "                break\n",
    "        if k > 0:\n",
    "            if p is not None:\n",
    "                print(\"%f \" % p[i].data.item(), end=\" \")\n",
    "            print()\n",
    "\n",
    "    print(\"Query:\")\n",
    "    for w in x_tilde:\n",
    "        print(QUERY.vocab.itos[w], end=\" \")\n",
    "    print()\n",
    "    if p_y is not None:\n",
    "        for i, p_y in enumerate(p_y):\n",
    "            print(\"%20s %f\" % (ANSWER.vocab.itos[i], py), end=\" \")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer:  bedroom\n",
      "Story: \n",
      "Daniel journeyed to the bedroom \n",
      "Daniel journeyed to the kitchen \n",
      "Query:\n",
      "Where is Daniel \n"
     ]
    }
   ],
   "source": [
    "x, x_tilde, y = next(wrap(val))\n",
    "display_instance(x[0], x_tilde[0], y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"Simple implementation of attention.\"\n",
    "\n",
    "    def __init__(\n",
    "        self, value_encoder, query_encoder, evidence_encoder=None, combiner=None\n",
    "    ):\n",
    "        super(Attention, self).__init__()\n",
    "        self.value_encoder = value_encoder\n",
    "        self.query_encoder = query_encoder\n",
    "\n",
    "        # If we have acess to the evidence (inference network)\n",
    "        self.evidence_encoder = evidence_encoder\n",
    "        self.combiner = combiner\n",
    "\n",
    "    def forward(self, src, query, evidence=None):\n",
    "        value_vecs = self.value_encoder(src)\n",
    "        query_vecs = self.query_encoder(query)\n",
    "        # Incorporate evidence if available\n",
    "        if self.evidence_encoder is not None:\n",
    "            evidence_vecs = self.answer_encoder(evidence)\n",
    "            query_vecs = self.combiner(torch.cat([query_vecs, evidence_vecs], -1))\n",
    "\n",
    "        # Apply attention.\n",
    "        attention_logits = torch.bmm(value_vecs, query_vecs.transpose(1, 2)).squeeze(-1)\n",
    "        return value_vecs, attention_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"A simple LSTM text encoder.\"\n",
    "\n",
    "    def __init__(self, vocab_size, hidden_size, last_only=False, pad=0):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab_size, hidden_size, padding_idx=pad)\n",
    "        self.encoder = nn.LSTM(\n",
    "            hidden_size=hidden_size, input_size=hidden_size, bidirectional=not last_only\n",
    "        )\n",
    "        self.last_only = last_only\n",
    "\n",
    "    def forward(self, text):\n",
    "        x = self.lut(text)\n",
    "        # If there is an extra dimension, sum it out.\n",
    "        if x.dim() >= 4:\n",
    "            x = x.sum(2)\n",
    "        x, _ = self.encoder(x)\n",
    "        return x[:, -1:] if self.last_only else x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(hidden_size = 100):\n",
    "    model = nn.Module()\n",
    "    \n",
    "    # Attention network between query and sentences.\n",
    "    model.alignment = Attention(\n",
    "        Encoder(len(STORY.vocab), hidden_size // 2, pad=STORY.vocab.stoi[\"pad\"]),\n",
    "        Encoder(len(QUERY.vocab), hidden_size, last_only=True, pad=STORY.vocab.stoi[\"pad\"]),\n",
    "    )\n",
    "    \n",
    "    # Prediction network given context.\n",
    "    model.generator = nn.Sequential(\n",
    "        nn.Linear(hidden_size, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, hidden_size),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size, len(ANSWER.vocab)),\n",
    "    )\n",
    "\n",
    "    # Inference network for the VAE model.\n",
    "    model.inference = Attention(\n",
    "        Encoder(len(STORY.vocab), hidden_size // 2, pad=STORY.vocab.stoi[\"pad\"]),\n",
    "        Encoder(len(QUERY.vocab), hidden_size, last_only=True, pad=STORY.vocab.stoi[\"pad\"]),\n",
    "        Encoder(len(ANSWER.vocab), hidden_size, last_only=True, pad=ANSWER.vocab.stoi[\"pad\"]),\n",
    "        nn.Sequential(nn.Linear(2 * hidden_size, hidden_size), nn.ReLU(), nn.Linear(hidden_size, hidden_size)),\n",
    "    )\n",
    "    model.cuda()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def E(p, v): \n",
    "    \"Compute expectation E_{z ~ p} ( v_z ).\"\n",
    "    return torch.bmm(p.unsqueeze(1), v)\n",
    "\n",
    "def KL(p, q): \n",
    "    \"KL divergence.\"\n",
    "    return ds.kl_divergence(p, q)\n",
    "\n",
    "# Aliases for categorical distributions.\n",
    "def Cat1(logits):\n",
    "    return ds.OneHotCategorical(logits=logits)\n",
    "\n",
    "def Cat(logits): \n",
    "    return ds.Categorical(logits=logits)\n",
    "\n",
    "def CatP(probs):\n",
    "    return ds.Categorical(probs=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, dataset, infer, epochs=50):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    for epoch in range(epochs):\n",
    "        for x, x_tilde, y in wrap(dataset):\n",
    "            opt.zero_grad()\n",
    "            # Compute the attention/alignment distribution p\n",
    "            v, theta = model.alignment.forward(x, x_tilde)\n",
    "            p = Cat1(theta)\n",
    "            \n",
    "            # Call infer with distribution and generator.\n",
    "            obj, p_y = infer(model.generator, x, x_tilde, y, p, v)\n",
    "            obj.mean().backward()\n",
    "            opt.step()\n",
    "            \n",
    "            # Check scores. \n",
    "            _, y_hat = p_y.probs.max(1)\n",
    "            correct = (y_hat == y).data.float().mean()\n",
    "        print(-p_y.log_prob(y).mean().detach().item(), correct.item() )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different types of inference methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft(f, x, x_tilde, y, p, v):\n",
    "    \"Compute soft attention i.e. y ~ Cat(f(E_p[v_z])).\"\n",
    "    context = E(p.probs, v)\n",
    "    p_y = Cat(f(context).squeeze(1))\n",
    "    return -p_y.log_prob(y), p_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard(f, x, x_tilde, y, p, v):\n",
    "    \"Compute simple hard attention.\"\n",
    "    choice = p.sample()\n",
    "    context = E(choice, v)\n",
    "    p_y = Cat(f(context).squeeze(1))\n",
    "    log_prob = p_y.log_prob(y) \n",
    "    reward = log_prob.detach()\n",
    "    return -(log_prob + p.log_prob(choice) * reward), p_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_soft(f, x, x_tilde, y, p, v):\n",
    "    \"Compute hard attention with a soft baseline.\"\n",
    "    choice = p.sample()\n",
    "    context = E(choice, v)\n",
    "    p_y = Cat(f(context).squeeze(1))\n",
    "    _, p_y_soft = soft(f, None, None, y, p, v)\n",
    "    log_prob = p_y.log_prob(y)\n",
    "    log_prob_soft = p_y_soft.log_prob(y)\n",
    "    reward = (log_prob - log_prob_soft).detach()\n",
    "    return -(log_prob + log_prob_soft + p.log_prob(choice) * reward), p_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enum(f, x, x_tilde, y, p, v):\n",
    "    \"Enumerate all possible outputs.\"\n",
    "    p_ys = Cat(f(v))\n",
    "    p_y = CatP(E(p.probs, p_ys.probs).squeeze(1))\n",
    "    return -p_y.log_prob(y), p_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_soft(f, x, x_tilde, y, p, v):\n",
    "    \"Compute the VAE based model with soft baseline\"\n",
    "    _, logits = model.inference(x, x_tilde, y.unsqueeze(1))\n",
    "    q = Cat1(logits)\n",
    "    choice = q.sample()\n",
    "    context = E(choice, v)\n",
    "    p_y = Cat(f(context).squeeze(1))\n",
    "    _, p_y_soft = soft(f, x, x_tilde, y, p, v)\n",
    "    log_prob = p_y.log_prob(y)\n",
    "    log_prob_soft = p_y_soft.log_prob(y)\n",
    "    reward = (log_prob - log_prob_soft).detach()\n",
    "    return -(log_prob + log_prob_soft + q.log_prob(choice) * reward - KL(q, p)), p_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7560386657714844 0.15000000596046448\n",
      "1.7189416885375977 0.20000000298023224\n",
      "1.408884882926941 0.5\n",
      "0.5281757116317749 0.9000000357627869\n",
      "0.0964445099234581 1.0\n",
      "0.11451363563537598 0.949999988079071\n",
      "0.014591860584914684 1.0\n",
      "0.010198927484452724 1.0\n",
      "0.0708063393831253 0.949999988079071\n",
      "0.01989584043622017 1.0\n",
      "0.010172558017075062 1.0\n",
      "0.0027688504196703434 1.0\n",
      "0.012838221155107021 1.0\n",
      "0.002007436705753207 1.0\n",
      "0.1813783496618271 0.949999988079071\n",
      "0.017470194026827812 1.0\n",
      "0.0030329227447509766 1.0\n",
      "0.006617713253945112 1.0\n",
      "0.0038623332511633635 1.0\n",
      "0.0015689373249188066 1.0\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "run_training(model, test, soft, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = vae\n",
    "x, x_tilde, y = next(wrap(test))\n",
    "v, theta = model.alignment.forward(x, x_tilde)\n",
    "p = Cat1(theta)\n",
    "loss, p_y = method(model.generator, x, x_tilde, y, p, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct answer:  hallway\n",
      "Story: \n",
      "      Mary  journeyed         to        the   bathroom 0.006361  \n",
      "      John  travelled         to        the    hallway 0.981357  \n",
      "Query:\n",
      "               Where                    is                  John  \n",
      "               <pad> 0.000000                  the 0.000000                   to 0.000000                 went 0.000000               Sandra 0.000000                 Mary 0.000000                 John 0.000000               Daniel 0.000000              hallway 0.000000            journeyed 0.000000                moved 0.000000            travelled 0.000000              bedroom 0.000000                 back 0.000000               garden 0.000000               office 0.000000              kitchen 0.000000             bathroom 0.000000                Where 0.000000                   is 0.000000 \n",
      "Correct answer:  bathroom\n",
      "Story: \n",
      "      John      moved         to        the    bedroom 0.042216  \n",
      "    Daniel       went       back         to        the   bathroom 0.014601  \n",
      "      Mary  journeyed         to        the   bathroom 0.940524  \n",
      "      John  travelled         to        the    hallway 0.002372  \n",
      "Query:\n",
      "               Where                    is                  Mary  \n",
      "               <pad> 0.000000                  the 0.000000                   to 0.000000                 went 0.000000               Sandra 0.000000                 Mary 0.000000                 John 0.000000               Daniel 0.000000              hallway 0.000000            journeyed 0.000000                moved 0.000000            travelled 0.000000              bedroom 0.000000                 back 0.000000               garden 0.000000               office 0.000000              kitchen 0.000000             bathroom 0.000000                Where 0.000000                   is 0.000000 \n",
      "Correct answer:  kitchen\n",
      "Story: \n",
      "    Sandra  journeyed         to        the    kitchen 0.999983  \n",
      "      John       went         to        the    hallway 0.000016  \n",
      "      John      moved         to        the    bedroom 0.000000  \n",
      "    Daniel       went       back         to        the   bathroom 0.000001  \n",
      "      Mary  journeyed         to        the   bathroom 0.000000  \n",
      "      John  travelled         to        the    hallway 0.000000  \n",
      "Query:\n",
      "               Where                    is                Sandra  \n",
      "               <pad> 0.000000                  the 0.000000                   to 0.000000                 went 0.000000               Sandra 0.000000                 Mary 0.000000                 John 0.000000               Daniel 0.000000              hallway 0.000000            journeyed 0.000000                moved 0.000000            travelled 0.000000              bedroom 0.000000                 back 0.000000               garden 0.000000               office 0.000000              kitchen 0.000000             bathroom 0.000000                Where 0.000000                   is 0.000000 \n",
      "Correct answer:  hallway\n",
      "Story: \n",
      "      John       went         to        the     garden 0.000080  \n",
      "    Sandra  travelled         to        the    hallway 0.990169  \n",
      "    Sandra  journeyed         to        the    kitchen 0.009751  \n",
      "      John       went         to        the    hallway 0.000001  \n",
      "      John      moved         to        the    bedroom 0.000000  \n",
      "    Daniel       went       back         to        the   bathroom 0.000000  \n",
      "      Mary  journeyed         to        the   bathroom 0.000000  \n",
      "      John  travelled         to        the    hallway 0.000000  \n",
      "Query:\n",
      "               Where                    is                Sandra  \n",
      "               <pad> 0.000000                  the 0.000000                   to 0.000000                 went 0.000000               Sandra 0.000000                 Mary 0.000000                 John 0.000000               Daniel 0.000000              hallway 0.000000            journeyed 0.000000                moved 0.000000            travelled 0.000000              bedroom 0.000000                 back 0.000000               garden 0.000000               office 0.000000              kitchen 0.000000             bathroom 0.000000                Where 0.000000                   is 0.000000 \n",
      "Correct answer:  kitchen\n",
      "Story: \n",
      "    Sandra      moved         to        the    kitchen 0.803700  \n",
      "    Sandra       went       back         to        the   bathroom 0.189644  \n",
      "      John       went         to        the     garden 0.000000  \n",
      "    Sandra  travelled         to        the    hallway 0.006464  \n",
      "    Sandra  journeyed         to        the    kitchen 0.000192  \n",
      "      John       went         to        the    hallway 0.000000  \n",
      "      John      moved         to        the    bedroom 0.000000  \n",
      "    Daniel       went       back         to        the   bathroom 0.000000  \n",
      "      Mary  journeyed         to        the   bathroom 0.000000  \n",
      "      John  travelled         to        the    hallway 0.000000  \n",
      "Query:\n",
      "               Where                    is                Sandra  \n",
      "               <pad> 0.000000                  the 0.000000                   to 0.000000                 went 0.000000               Sandra 0.000000                 Mary 0.000000                 John 0.000000               Daniel 0.000000              hallway 0.000000            journeyed 0.000000                moved 0.000000            travelled 0.000000              bedroom 0.000000                 back 0.000000               garden 0.000000               office 0.000000              kitchen 0.000000             bathroom 0.000000                Where 0.000000                   is 0.000000 \n",
      "Correct answer:  hallway\n",
      "Story: \n",
      "    Sandra  travelled         to        the    hallway 0.704217  \n",
      "    Sandra  travelled         to        the    kitchen 0.295783  \n",
      "Query:\n",
      "               Where                    is                Sandra  \n",
      "               <pad> 0.000000                  the 0.000000                   to 0.000000                 went 0.000000               Sandra 0.000000                 Mary 0.000000                 John 0.000000               Daniel 0.000000              hallway 0.000000            journeyed 0.000000                moved 0.000000            travelled 0.000000              bedroom 0.000000                 back 0.000000               garden 0.000000               office 0.000000              kitchen 0.000000             bathroom 0.000000                Where 0.000000                   is 0.000000 \n",
      "Correct answer:  garden\n",
      "Story: \n",
      "    Sandra      moved         to        the     garden 0.997801  \n",
      "      Mary       went         to        the   bathroom 0.000006  \n",
      "    Sandra  travelled         to        the    hallway 0.001168  \n",
      "    Sandra  travelled         to        the    kitchen 0.001025  \n",
      "Query:\n",
      "               Where                    is                Sandra  \n",
      "               <pad> 0.000000                  the 0.000000                   to 0.000000                 went 0.000000               Sandra 0.000000                 Mary 0.000000                 John 0.000000               Daniel 0.000000              hallway 0.000000            journeyed 0.000000                moved 0.000000            travelled 0.000000              bedroom 0.000000                 back 0.000000               garden 0.000000               office 0.000000              kitchen 0.000000             bathroom 0.000000                Where 0.000000                   is 0.000000 \n",
      "Correct answer:  hallway\n",
      "Story: \n",
      "    Daniel  journeyed         to        the    hallway 0.999981  \n",
      "    Sandra  travelled         to        the     office 0.000017  \n",
      "    Sandra      moved         to        the     garden 0.000000  \n",
      "      Mary       went         to        the   bathroom 0.000001  \n",
      "    Sandra  travelled         to        the    hallway 0.000000  \n",
      "    Sandra  travelled         to        the    kitchen 0.000000  \n",
      "Query:\n",
      "               Where                    is                Daniel  \n",
      "               <pad> 0.000000                  the 0.000000                   to 0.000000                 went 0.000000               Sandra 0.000000                 Mary 0.000000                 John 0.000000               Daniel 0.000000              hallway 0.000000            journeyed 0.000000                moved 0.000000            travelled 0.000000              bedroom 0.000000                 back 0.000000               garden 0.000000               office 0.000000              kitchen 0.000000             bathroom 0.000000                Where 0.000000                   is 0.000000 \n",
      "Correct answer:  office\n",
      "Story: \n",
      "      John      moved         to        the    hallway 0.000146  \n",
      "    Daniel  journeyed         to        the     office 0.000396  \n",
      "    Daniel  journeyed         to        the    hallway 0.000043  \n",
      "    Sandra  travelled         to        the     office 0.982225  \n",
      "    Sandra      moved         to        the     garden 0.017056  \n",
      "      Mary       went         to        the   bathroom 0.000001  \n",
      "    Sandra  travelled         to        the    hallway 0.000047  \n",
      "    Sandra  travelled         to        the    kitchen 0.000087  \n",
      "Query:\n",
      "               Where                    is                Sandra  \n",
      "               <pad> 0.000000                  the 0.000000                   to 0.000000                 went 0.000000               Sandra 0.000000                 Mary 0.000000                 John 0.000000               Daniel 0.000000              hallway 0.000000            journeyed 0.000000                moved 0.000000            travelled 0.000000              bedroom 0.000000                 back 0.000000               garden 0.000000               office 0.000000              kitchen 0.000000             bathroom 0.000000                Where 0.000000                   is 0.000000 \n",
      "Correct answer:  office\n",
      "Story: \n",
      "      John  journeyed         to        the     office 0.009519  \n",
      "      John  travelled         to        the   bathroom 0.002485  \n",
      "      John      moved         to        the    hallway 0.000087  \n",
      "    Daniel  journeyed         to        the     office 0.902627  \n",
      "    Daniel  journeyed         to        the    hallway 0.085267  \n",
      "    Sandra  travelled         to        the     office 0.000010  \n",
      "    Sandra      moved         to        the     garden 0.000000  \n",
      "      Mary       went         to        the   bathroom 0.000005  \n",
      "    Sandra  travelled         to        the    hallway 0.000000  \n",
      "    Sandra  travelled         to        the    kitchen 0.000000  \n",
      "Query:\n",
      "               Where                    is                Daniel  \n",
      "               <pad> 0.000000                  the 0.000000                   to 0.000000                 went 0.000000               Sandra 0.000000                 Mary 0.000000                 John 0.000000               Daniel 0.000000              hallway 0.000000            journeyed 0.000000                moved 0.000000            travelled 0.000000              bedroom 0.000000                 back 0.000000               garden 0.000000               office 0.000000              kitchen 0.000000             bathroom 0.000000                Where 0.000000                   is 0.000000 \n"
     ]
    }
   ],
   "source": [
    "for j in range(0,10):\n",
    "    display_instance(x[j], x_tilde[j], y[j], p.probs[j], p_y.probs[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
